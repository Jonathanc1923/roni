<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Roni - Tu Amigo Virtual</title>
    <style>
        body {
            font-family: Arial, sans-serif;
            text-align: center;
            margin-top: 50px;
        }
        button {
            font-size: 16px;
            padding: 10px 20px;
            margin: 10px;
        }
        #status {
            font-size: 14px;
            margin-top: 10px;
            color: #555;
        }
    </style>
</head>
<body>
    <h1>Roni - Tu Amigo Virtual</h1>
    <button id="record">🎤 Grabar</button>
    <div id="status">Estado: Listo para grabar</div>
    <div id="transcription"></div>
    <div id="response"></div>
    <audio id="responseAudio" controls style="display: none;"></audio>

    <script>
        const recordButton = document.getElementById("record");
        const status = document.getElementById("status");
        const transcription = document.getElementById("transcription");
        const response = document.getElementById("response");
        const responseAudio = document.getElementById("responseAudio");

        let mediaRecorder;
        let audioChunks = [];
        let isRecording = false;

        // Función para convertir audio WebM en WAV con 16 kHz
        async function convertWebMToWAV16KHz(blob) {
            const audioContext = new AudioContext();
            const arrayBuffer = await blob.arrayBuffer();
            const audioBuffer = await audioContext.decodeAudioData(arrayBuffer);

            // Reescalar a 16 kHz
            const offlineAudioContext = new OfflineAudioContext(
                1, // Mono
                Math.ceil(audioBuffer.duration * 16000), // Total de muestras a 16 kHz
                16000 // Nueva frecuencia de muestreo
            );
            const source = offlineAudioContext.createBufferSource();
            source.buffer = audioBuffer;
            source.connect(offlineAudioContext.destination);
            source.start(0);
            const renderedBuffer = await offlineAudioContext.startRendering();

            // Crear un WAV válido
            return encodeWAV(renderedBuffer.getChannelData(0), 16000);
        }

        // Función para encapsular datos en formato WAV
        function encodeWAV(samples, sampleRate) {
            const buffer = new ArrayBuffer(44 + samples.length * 2);
            const view = new DataView(buffer);

            function writeString(view, offset, string) {
                for (let i = 0; i < string.length; i++) {
                    view.setUint8(offset + i, string.charCodeAt(i));
                }
            }

            writeString(view, 0, "RIFF");
            view.setUint32(4, 36 + samples.length * 2, true);
            writeString(view, 8, "WAVE");
            writeString(view, 12, "fmt ");
            view.setUint32(16, 16, true);
            view.setUint16(20, 1, true);
            view.setUint16(22, 1, true);
            view.setUint32(24, sampleRate, true);
            view.setUint32(28, sampleRate * 2, true);
            view.setUint16(32, 2, true);
            view.setUint16(34, 16, true);
            writeString(view, 36, "data");
            view.setUint32(40, samples.length * 2, true);

            const offset = 44;
            for (let i = 0; i < samples.length; i++) {
                const s = Math.max(-1, Math.min(1, samples[i]));
                view.setInt16(offset + i * 2, s < 0 ? s * 0x8000 : s * 0x7FFF, true);
            }

            return new Blob([buffer], { type: "audio/wav" });
        }

        recordButton.addEventListener("click", async () => {
            if (!isRecording) {
                try {
                    const stream = await navigator.mediaDevices.getUserMedia({ audio: true });
                    mediaRecorder = new MediaRecorder(stream);
                    audioChunks = [];
                    isRecording = true;

                    mediaRecorder.ondataavailable = (event) => {
                        audioChunks.push(event.data);
                    };

                    // Dentro de mediaRecorder.onstop
mediaRecorder.onstop = async () => {
    isRecording = false;
    const audioBlob = new Blob(audioChunks, { type: "audio/webm" });
    const wavBlob = await convertWebMToWAV16KHz(audioBlob); // Convertir a WAV con 16 kHz
    const formData = new FormData();
    formData.append("file", wavBlob, "temp_audio.wav");

    status.textContent = "Enviando audio al servidor...";
    const response = await fetch("/process-audio", {
        method: "POST",
        body: formData,
    });

    const result = await response.json();
    if (result.error) {
        status.textContent = `Error: ${result.error}`;
    } else {
        transcription.textContent = `Transcripción: ${result.transcription}`;
        response.textContent = `Respuesta: ${result.response}`;
        
        // Corregido: Configurar correctamente la fuente del audio generado
        responseAudio.src = "/audio-response"; // URL fija que apunta al endpoint del servidor
        responseAudio.style.display = "block"; // Mostrar el reproductor de audio
        responseAudio.load(); // Cargar el audio
        responseAudio.play(); // Reproducir automáticamente el audio

        status.textContent = "Respuesta recibida.";
    }
};


                    mediaRecorder.start();
                    status.textContent = "Grabando... Presiona de nuevo para detener.";
                } catch (error) {
                    console.error("Error al acceder al micrófono:", error);
                    status.textContent = "Error al acceder al micrófono.";
                }
            } else {
                mediaRecorder.stop();
                status.textContent = "Procesando grabación...";
            }
        });
    </script>
</body>
</html>